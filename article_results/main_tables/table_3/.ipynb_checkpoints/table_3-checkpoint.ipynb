{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from comet_ml import Experiment\n",
    "import numpy as np\n",
    "from numpy import inf, ndarray\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import keras\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import re\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model, Model\n",
    "from tempfile import TemporaryFile\n",
    "from keras import layers\n",
    "from keras.callbacks import History, ReduceLROnPlateau\n",
    "from keras.layers import Input, BatchNormalization, Activation\n",
    "from keras.layers import CuDNNLSTM, Dense, Bidirectional, Dropout, Layer\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.regularizers import l2\n",
    "from functools import partial\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from copy import deepcopy\n",
    "from math import ceil\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Define custom metrics for evaluation\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "def get_cindex(y_true, y_pred):\n",
    "    g = tf.subtract(tf.expand_dims(y_pred, -1), y_pred)\n",
    "    g = tf.cast(g == 0.0, tf.float32) * 0.5 + tf.cast(g > 0.0, tf.float32)\n",
    "\n",
    "    f = tf.subtract(tf.expand_dims(y_true, -1), y_true) > 0.0\n",
    "    f = tf.matrix_band_part(tf.cast(f, tf.float32), -1, 0)\n",
    "\n",
    "    g = tf.reduce_sum(tf.multiply(g, f))\n",
    "    f = tf.reduce_sum(f)\n",
    "\n",
    "    return tf.where(tf.equal(g, 0), 0.0, g/f)\n",
    "\n",
    "def pearson_r(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x, axis=0)\n",
    "    my = K.mean(y, axis=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = K.sum(xm * ym)\n",
    "    x_square_sum = K.sum(xm * xm)\n",
    "    y_square_sum = K.sum(ym * ym)\n",
    "    r_den = K.sqrt(x_square_sum * y_square_sum)\n",
    "    r = r_num / r_den\n",
    "    return K.mean(r)\n",
    "\n",
    "def mse_sliced(th):\n",
    "    def mse_similars(y_true,y_pred):\n",
    "        condition = K.tf.math.less_equal(y_pred,th)\n",
    "        indices = K.tf.where(condition)\n",
    "        slice_true = K.tf.gather_nd(y_true,indices)\n",
    "        slice_pred = K.tf.gather_nd(y_pred,indices)\n",
    "        mse_sliced = K.mean(K.square(slice_pred - slice_true), axis=-1)\n",
    "        return mse_sliced\n",
    "    return mse_similars\n",
    "\n",
    "#Model evaluation function\n",
    "def model_evaluate(y_pred,Y_cold,thresh,df_cold):\n",
    "    true = np.reshape(Y_cold,len(df_cold))\n",
    "    pred = np.reshape(y_pred,len(df_cold))\n",
    "    cor = np.corrcoef(true,pred)\n",
    "    mse_all = sklearn.metrics.mean_squared_error(true,pred)\n",
    "    # calculate mse of similars\n",
    "    if (len(pred[np.where(pred<=thresh)])>0):\n",
    "        mse_sims = sklearn.metrics.mean_squared_error(true[pred<=thresh],pred[pred<=thresh])\n",
    "    else:\n",
    "        mse_sims = \"None\"\n",
    "    # turn to categorical to calculate precision and accuracy\n",
    "    true_cat = true <= thresh\n",
    "    pred_cat = pred <= thresh\n",
    "    pos = np.sum(pred_cat)\n",
    "    if (len(pred[np.where(pred<=thresh)])>0):\n",
    "        prec = precision_score(true_cat,pred_cat)\n",
    "    else: \n",
    "        prec = \"None\"\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(true_cat,pred_cat)\n",
    "    result =pd.DataFrame({'cor' : cor[0,1], 'mse_all' : mse_all, 'mse_similars' : mse_sims,'precision': prec, 'accuracy': acc,\n",
    "                         'positives' : pos}, index=[0])\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSIBA a375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cor</th>\n",
       "      <th>mse_all</th>\n",
       "      <th>mse_similars</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.589977</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>0.982249</td>\n",
       "      <td>0.83424</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cor   mse_all  mse_similars  precision  accuracy  positives\n",
       "0  0.589977  0.008314      0.005944   0.982249   0.83424        169"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.read_csv(\"C:/Users/user/Documents/deepSIBA/learning/data/a375/train_test_split/test.csv\")\n",
    "model_evaluate(np.array(preds[\"V1\"]),np.array(preds[\"value\"]),0.2,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSIBA vcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cor</th>\n",
       "      <th>mse_all</th>\n",
       "      <th>mse_similars</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.414126</td>\n",
       "      <td>0.03297</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.716312</td>\n",
       "      <td>0.854016</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cor  mse_all  mse_similars  precision  accuracy  positives\n",
       "0  0.414126  0.03297      0.001919   0.716312  0.854016        141"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.read_csv(\"C:/Users/user/Documents/deepSIBA/learning/data/vcap/train_test_split/test.csv\")\n",
    "model_evaluate(np.array(preds[\"V1\"]),np.array(preds[\"value\"]),0.2,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSIBA pc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cor</th>\n",
       "      <th>mse_all</th>\n",
       "      <th>mse_similars</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5259</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.858997</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cor   mse_all  mse_similars  precision  accuracy  positives\n",
       "0  0.5259  0.011188      0.010994   0.892857  0.858997         28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.read_csv(\"C:/Users/user/Documents/deepSIBA/learning/data/pc3/train_test_split/test.csv\")\n",
    "model_evaluate(np.array(preds[\"V1\"]),np.array(preds[\"value\"]),0.2,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSIBA mcf7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cor</th>\n",
       "      <th>mse_all</th>\n",
       "      <th>mse_similars</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.557064</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.610256</td>\n",
       "      <td>0.874274</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cor   mse_all  mse_similars  precision  accuracy  positives\n",
       "0  0.557064  0.011587      0.004596   0.610256  0.874274        195"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.read_csv(\"C:/Users/user/Documents/deepSIBA/learning/data/mcf7/train_test_split/test.csv\")\n",
    "model_evaluate(np.array(preds[\"V1\"]),np.array(preds[\"value\"]),0.2,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
