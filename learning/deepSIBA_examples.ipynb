{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSIBA example 1 : Train ensemble\n",
    "In this example a deepSIBA ensemble model will be trained from scratch using the model_params and train_params dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"max_atoms\" : int(60), \"num_atom_features\" : int(62), \"max_degree\" : int(5), \"num_bond_features\" : int(6),\n",
    "    \"graph_conv_width\" : [128,128,128], \"conv1d_filters\" : int(128), \"conv1d_size\" : int(29), \"dropout_encoder\" : 0.25,\n",
    "    \"conv1d_filters_dist\" : [128,128], \"conv1d_size_dist\" : [17,1], \"dropout_dist\" : 0.25, \"pool_size\" : int(4),\n",
    "    \"dense_size\" : [256,128,128], \"l2reg\" : 0.01, \"dist_thresh\" : 0.2, \"lr\" : 0.001 \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model_params dictionary contains the parameters to build the deepSIBA siamese GCN architecture, more specifically:\n",
    "1. **max_atoms, num_atom_features, max_degree and num_bond_features** refer to the parameters needed to featurize the input chemical structures. For more information, refer to the *ESI of the deepSIBA publication*.\n",
    "2. **graph_conv_width, conv1d_filters, conv1d_size, dropout_encoder** refer to the parameters of the siamese graph encoders.\n",
    "3. **conv1d_filters_dist, conv1d_size_dist, dropout_dist, pool_size, dense_size, l2reg** refer to the parameters of the distance module.\n",
    "4. **dist_thresh** is the distance threshold to consider 2 chemical structures similar in biological effect (needed for custom training metrics).\n",
    "5. **lr** is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"cell_line\" : \"a375\", \"split\" : \"train_test_split\", \"number_folds\" : [0],\n",
    "    \"output_dir\" : \"C:/Users/user/Documents/deepSIBA/results/test1\",\n",
    "    \"batch_size\" : int(128), \"epochs\" : int(20), \n",
    "    \"N_ensemble\" : int(5), \"nmodel_start\" : int(2), \"prec_threshold\" : 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_params dictionary contains the parameters required to train deepSIBA:\n",
    "1. **cell_line** is the cellular model of choice out of **(a375,pc3,vcap,mcf7)** for which we have enough available data. Later a merged option will be added.\n",
    "2. **split** is one of **(train_test_split,5_fold_cv_split)**. The data to train the models are available in this **drive link**.\n",
    "3. **number_folds** is a list, if split == train_test_split the number_folds should be [0]. If the split is a 5_fold_cv_split the number_folds should be [0,1,2,3,4] in order to train the model in all splits. If you want to train a model on a specific fold, e.g. the 3rd one, the number_folds should be [2].\n",
    "4. **output_dir** is the full path to the specified output directory.\n",
    "5. **N_ensemble** is the number of models to train and include in the ensemble.\n",
    "6. **nmodel_start** this should be set to 0 if training for the first time, but if training is halted, nmodel_start specifies the model number in the ensemble to start training from.\n",
    "7. **prec_threshold** is the distance threshold to consider 2 chemical structures similar in biological effect (needed for custom training metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from deepSIBA_train import siba_trainer\n",
    "example_1 = siba_trainer(train_params, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSIBA example 2 : Load trained ensemble and predict\n",
    "In this example a trained deepSIBA ensemble model will be loaded and used to make predictions for the appropriate test set.\n",
    "For each of the cell lines, trained ensembles of either 50 or 10 models for all available splits, can be found in **drive link**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
