{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "U_wj_agB2hEl",
    "outputId": "f7e012a3-8926-49c6-ad0c-6a0dedaa636c"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "from numpy import inf, ndarray\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import keras\n",
    "import re\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model, Model\n",
    "from tempfile import TemporaryFile\n",
    "from keras import layers\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors\n",
    "from matplotlib import pyplot as plt\n",
    "# matplotlib inline\n",
    "from keras.callbacks import History, ReduceLROnPlateau\n",
    "from keras.layers import Input, BatchNormalization, Activation\n",
    "from keras.layers import CuDNNLSTM, Dense, Bidirectional, Dropout, Layer\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.regularizers import l2\n",
    "from functools import partial\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from copy import deepcopy\n",
    "from NGF.utils import filter_func_args, mol_shapes_to_dims\n",
    "import NGF.utils\n",
    "import NGF_layers.features\n",
    "import NGF_layers.graph_layers\n",
    "from NGF_layers.features import one_of_k_encoding, one_of_k_encoding_unk, atom_features, bond_features, num_atom_features, num_bond_features\n",
    "from NGF_layers.features import padaxis, tensorise_smiles, concat_mol_tensors\n",
    "from NGF_layers.graph_layers import temporal_padding, neighbour_lookup, NeuralGraphHidden, NeuralGraphOutput\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oExpmpae2hFU",
    "outputId": "1dc4e7b9-cce9-4bf4-b955-137785d4c6ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following GPU devices are available: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)\n",
    "\n",
    "# Check available GPU devices.\n",
    "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtZmJPQC2hFY"
   },
   "source": [
    "# Load all smiles of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bl7_jPHu2hFZ"
   },
   "outputs": [],
   "source": [
    "#Load unique smiles and tensorize them\n",
    "smiles = pd.read_csv('../../deepSIBA/learning/data/mcf7/mcf7q1smiles.csv',index_col=0)\n",
    "\n",
    "X_atoms, X_bonds, X_edges = tensorise_smiles(smiles.x, max_degree=5, max_atoms = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwSjrDWa2hFc"
   },
   "outputs": [],
   "source": [
    "smiles=list(smiles['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrLlOODn2hHE"
   },
   "outputs": [],
   "source": [
    "#num_molecules = len(df)\n",
    "max_atoms = 60\n",
    "max_degree = 5\n",
    "num_atom_features = 62\n",
    "num_bond_features = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vj8ZLfGt2hHJ"
   },
   "source": [
    "\n",
    "# Define custom loss and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWkUOMFx2hHK"
   },
   "outputs": [],
   "source": [
    "def custom_loss(sigma):\n",
    "    def gaussian_loss(y_true, y_pred):\n",
    "        return tf.reduce_mean(0.5*tf.log(sigma) + 0.5*tf.div(tf.square(y_true - y_pred), sigma)) + 1e-6\n",
    "    return gaussian_loss\n",
    "\n",
    "class GaussianLayer(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(GaussianLayer, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.kernel_1 = self.add_weight(name='kernel_1', \n",
    "                                      shape=(128, self.output_dim),\n",
    "                                      initializer=glorot_normal(),\n",
    "                                      trainable=True)\n",
    "        self.kernel_2 = self.add_weight(name='kernel_2', \n",
    "                                      shape=(128, self.output_dim),\n",
    "                                      initializer=glorot_normal(),\n",
    "                                      trainable=True)\n",
    "        self.bias_1 = self.add_weight(name='bias_1',\n",
    "                                    shape=(self.output_dim, ),\n",
    "                                    initializer=glorot_normal(),\n",
    "                                    trainable=True)\n",
    "        self.bias_2 = self.add_weight(name='bias_2',\n",
    "                                    shape=(self.output_dim, ),\n",
    "                                    initializer=glorot_normal(),\n",
    "                                    trainable=True)\n",
    "        super(GaussianLayer, self).build(input_shape) \n",
    "    def call(self, x):\n",
    "        output_mu  = K.dot(x, self.kernel_1) + self.bias_1\n",
    "        output_sig = K.dot(x, self.kernel_2) + self.bias_2\n",
    "        output_sig_pos = K.log(1 + K.exp(output_sig)) + 1e-06  \n",
    "        return [output_mu, output_sig_pos]\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(input_shape[0], self.output_dim), (input_shape[0], self.output_dim)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZ5eGXTz2hHN"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feIJEJOp2hHQ"
   },
   "outputs": [],
   "source": [
    "p = {'lr': 0.0001,\n",
    "     'nfilters': int(32),\n",
    "     'size': int(8),\n",
    "     'conv_width' : 128,\n",
    "     'fp_length' : 256,\n",
    "     'size_drug_1' : 8,\n",
    "     'size_drug_2' : 4,\n",
    "     'size_protein_1' : 8,\n",
    "     'size_protein_2' : 16,\n",
    "     'size_protein_3' : 3,\n",
    "     'batch_size': int(128),\n",
    "     'dense_size': int(256),\n",
    "     'dense_size_2': 512,\n",
    "     'dropout': 0.25,\n",
    "     'l2reg': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xu79Agkp2hHY"
   },
   "outputs": [],
   "source": [
    "def enc_nikos(params, lr_value, conv_width, fp_length):\n",
    "        \n",
    "    ### encode smiles\n",
    "    \n",
    "    atoms0 = Input(name='atom_inputs', shape=(max_atoms, num_atom_features),dtype = 'float32')\n",
    "    bonds = Input(name='bond_inputs', shape=(max_atoms, max_degree, num_bond_features),dtype = 'float32')\n",
    "    edges = Input(name='edge_inputs', shape=(max_atoms, max_degree), dtype='int32')\n",
    "\n",
    "    g1 = NeuralGraphHidden(conv_width , activ = None, bias = True , init = 'glorot_normal')([atoms0,bonds,edges])\n",
    "    g1 = BatchNormalization(momentum=0.6)(g1)\n",
    "    g1 = Activation('relu')(g1)\n",
    "    #g1 = keras.layers.Dropout(0.25)(g1) #this enables dropout also in test-time\n",
    "    g2 = NeuralGraphHidden(conv_width , activ = None, bias = True , init = 'glorot_normal')([g1,bonds,edges])\n",
    "    g2 = BatchNormalization(momentum=0.6)(g2)\n",
    "    g2 = Activation('relu')(g2)\n",
    "    #g2 =keras.layers.Dropout(0.25)(g2)\n",
    "    g3 = NeuralGraphHidden(conv_width , activ = None, bias = True , init = 'glorot_normal')([g2,bonds,edges])\n",
    "    g3 = BatchNormalization(momentum=0.6)(g3)\n",
    "    g3 = Activation('relu')(g3)\n",
    "    #g3 =keras.layers.Dropout(0.25)(g3)\n",
    "    \n",
    "    g4=keras.layers.Conv1D(128, 29, activation=None, use_bias=False, kernel_initializer='glorot_uniform')(g3)\n",
    "    g4= BatchNormalization(momentum=0.6)(g4)\n",
    "    g4 = Activation('relu')(g4)\n",
    "    g4=keras.layers.Dropout(0.25)(g4)\n",
    "    \n",
    "\n",
    "    #End of encoding\n",
    "    interactionModel = keras.Model(inputs=[atoms0, bonds, edges], outputs= g4)\n",
    "\n",
    "    print(interactionModel.summary())\n",
    "    return interactionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CCSwhxs02hHc",
    "outputId": "d1f5a1c2-8a65-4579-d787-30df8463b768"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1019 16:29:43.066511 139735556601664 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1019 16:29:43.069628 139735556601664 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1019 16:29:43.070543 139735556601664 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1019 16:29:43.190006 139735556601664 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1019 16:29:43.503687 139735556601664 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1019 16:29:43.562798 139735556601664 deprecation.py:506] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs (InputLayer)        (None, 60, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs (InputLayer)        (None, 60, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs (InputLayer)        (None, 60, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "neural_graph_hidden_1 (NeuralGr (None, 60, 128)      44160       atom_inputs[0][0]                \n",
      "                                                                 bond_inputs[0][0]                \n",
      "                                                                 edge_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 60, 128)      512         neural_graph_hidden_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 60, 128)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "neural_graph_hidden_2 (NeuralGr (None, 60, 128)      86400       activation_1[0][0]               \n",
      "                                                                 bond_inputs[0][0]                \n",
      "                                                                 edge_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 60, 128)      512         neural_graph_hidden_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 60, 128)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "neural_graph_hidden_3 (NeuralGr (None, 60, 128)      86400       activation_2[0][0]               \n",
      "                                                                 bond_inputs[0][0]                \n",
      "                                                                 edge_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 60, 128)      512         neural_graph_hidden_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 60, 128)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 32, 128)      475136      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 128)      512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 128)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 128)      0           activation_4[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 694,144\n",
      "Trainable params: 693,120\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:29:44.397294 139735556601664 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1019 16:29:44.758790 139735556601664 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1019 16:29:44.761974 139735556601664 deprecation.py:323] From <ipython-input-12-c43ce433651a>:3: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs_1 (InputLayer)      (None, 60, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_1 (InputLayer)      (None, 60, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_1 (InputLayer)      (None, 60, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_2 (InputLayer)      (None, 60, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_2 (InputLayer)      (None, 60, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_2 (InputLayer)      (None, 60, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 32, 128)      694144      atom_inputs_1[0][0]              \n",
      "                                                                 bond_inputs_1[0][0]              \n",
      "                                                                 edge_inputs_1[0][0]              \n",
      "                                                                 atom_inputs_2[0][0]              \n",
      "                                                                 bond_inputs_2[0][0]              \n",
      "                                                                 edge_inputs_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32, 128)      0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 16, 128)      278528      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 128)      512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 128)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 128)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 16, 128)      16384       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 128)      512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 128)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 128)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 4, 128)       0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 128)       512         max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          131328      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128)          512         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          16512       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128)          512         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "main_output (GaussianLayer)     [(None, 1), (None, 1 258         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,173,634\n",
      "Trainable params: 1,170,818\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Initialize encoder\n",
    "encoder_nikos = enc_nikos(p, 0.001, 128, 256)\n",
    "    \n",
    "# Initialize model\n",
    "atoms0_1 = Input(name='atom_inputs_1', shape=(max_atoms, num_atom_features),dtype = 'float32')\n",
    "bonds_1 = Input(name='bond_inputs_1', shape=(max_atoms, max_degree, num_bond_features),dtype = 'float32')\n",
    "edges_1 = Input(name='edge_inputs_1', shape=(max_atoms, max_degree), dtype='int32')\n",
    "\n",
    "atoms0_2 = Input(name='atom_inputs_2', shape=(max_atoms, num_atom_features),dtype = 'float32')\n",
    "bonds_2 = Input(name='bond_inputs_2', shape=(max_atoms, max_degree, num_bond_features),dtype = 'float32')\n",
    "edges_2 = Input(name='edge_inputs_2', shape=(max_atoms, max_degree), dtype='int32')\n",
    "\n",
    "encoded_1 = encoder_nikos([atoms0_1,bonds_1,edges_1])\n",
    "encoded_2 = encoder_nikos([atoms0_2,bonds_2,edges_2])\n",
    "\n",
    "L1_layer = keras.layers.Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "L1_distance = L1_layer([encoded_1, encoded_2])\n",
    "\n",
    "fc1=keras.layers.Conv1D(128, 17, activation=None, use_bias=False, kernel_initializer='glorot_uniform')(L1_distance)\n",
    "fc1= BatchNormalization(momentum=0.6)(fc1)\n",
    "fc1= Activation('relu')(fc1)\n",
    "fc1=keras.layers.Dropout(0.25)(fc1)\n",
    "\n",
    "fc2=keras.layers.Conv1D(128, 1, activation=None, use_bias=False, kernel_initializer='glorot_uniform')(fc1)\n",
    "fc2= BatchNormalization(momentum=0.6)(fc2)\n",
    "fc2= Activation('relu')(fc2)\n",
    "fc2=keras.layers.Dropout(0.25)(fc2)\n",
    "\n",
    "\n",
    "fc3=keras.layers.MaxPooling1D(pool_size= 4, strides=None, padding='valid', data_format='channels_last')(fc2)\n",
    "fc3 = BatchNormalization(momentum=0.6)(fc3)\n",
    "fc3=keras.layers.Flatten()(fc3)\n",
    "\n",
    "fc4 = keras.layers.Dense(256,activation = None,kernel_regularizer=regularizers.l2(p['l2reg']), kernel_initializer='glorot_normal')(fc3)\n",
    "fc4 = BatchNormalization(momentum=0.6)(fc4)\n",
    "fc4 = Activation('relu')(fc4)\n",
    "fc4 = keras.layers.Dropout(0.25)(fc4)\n",
    "\n",
    "\n",
    "fc5 = keras.layers.Dense(128,activation = None,kernel_regularizer=regularizers.l2(p['l2reg']), kernel_initializer='glorot_normal')(fc4)\n",
    "fc5 = BatchNormalization(momentum=0.6)(fc5)\n",
    "fc5 = Activation('relu')(fc5)\n",
    "fc5 = keras.layers.Dropout(0.25)(fc5)\n",
    "\n",
    "fc6 = keras.layers.Dense(128,activation = None,kernel_regularizer=regularizers.l2(p['l2reg']), kernel_initializer='glorot_normal')(fc5)\n",
    "fc6 = BatchNormalization(momentum=0.6)(fc6)\n",
    "fc6 = Activation('relu')(fc6)\n",
    "fc6 = keras.layers.Dropout(0.25)(fc6)\n",
    "\n",
    "\n",
    "mu, sigma = GaussianLayer(1, name='main_output')(fc6)\n",
    "\n",
    "\n",
    "siamese_net = Model(inputs=[atoms0_1,bonds_1,edges_1,atoms0_2,bonds_2,edges_2],outputs=mu)\n",
    "print(siamese_net.summary())\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "siamese_net.compile(optimizer= adam,loss= custom_loss(sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries for visualization later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S2woYv6k2hH7",
    "outputId": "5ab9dfff-a0fe-4421-b8c2-c609a11397cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018.09.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.display import SVG\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions #Only needed if modifying defaults\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "from rdkit import rdBase\n",
    "from rdkit.RDPaths import RDDocsDir\n",
    "from rdkit.RDPaths import RDDataDir\n",
    "import os\n",
    "from rdkit.Chem import AllChem\n",
    "print(rdBase.rdkitVersion)\n",
    "IPythonConsole.ipython_useSVG=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upru8NKM2hH_"
   },
   "outputs": [],
   "source": [
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "def moltosvg(mol,molSize=(450,150),kekulize=True):\n",
    "    mc = Chem.Mol(mol.ToBinary())\n",
    "    if kekulize:\n",
    "        try:\n",
    "            Chem.Kekulize(mc)\n",
    "        except:\n",
    "            mc = Chem.Mol(mol.ToBinary())\n",
    "    if not mc.GetNumConformers():\n",
    "        rdDepictor.Compute2DCoords(mc)\n",
    "    drawer = rdMolDraw2D.MolDraw2DSVG(molSize[0],molSize[1])\n",
    "    drawer.DrawMolecule(mc)\n",
    "    drawer.FinishDrawing()\n",
    "    svg = drawer.GetDrawingText()\n",
    "    # It seems that the svg renderer used doesn't quite hit the spec.\n",
    "    # Here are some fixes to make it work in the notebook, although I think\n",
    "    # the underlying issue needs to be resolved at the generation step\n",
    "    return svg.replace('svg:','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for important atoms visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoms_colors(m1,atoms_grad,colors_at,num_atoms):\n",
    "    atom_ind=[]\n",
    "    for i in range(num_atoms):\n",
    "        if atoms_grad[i]>np.mean(atoms_grad):\n",
    "        #if atoms_grad[i]>0:\n",
    "            #c=tuple(((atoms_grad[i]-np.min(atoms_grad))/(np.max(atoms_grad)-np.min(atoms_grad)))[0]*a+b for a,b in zip((0,-1,0),(1,1,0)))\n",
    "            #c=tuple(((atoms_grad[i]-np.min(atoms_grad))/(np.max(atoms_grad)-np.min(atoms_grad)))*a+b for a,b in zip((0,-1,0),(1,1,0)))\n",
    "            c=tuple(((atoms_grad[i]-np.mean(atoms_grad))/(np.max(atoms_grad)-np.mean(atoms_grad)))*a+b for a,b in zip((0,-1,0),(1,1,0)))\n",
    "            colors_at.update( {i : c} )\n",
    "            atom_ind.append(i)\n",
    "    return(colors_at,atom_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fludarabine\n",
    "smi_query=[\"Nc1nc(F)nc2c1ncn2C1OC(CO)C(O)C1O\"]\n",
    "smis_list=[\"Cn1cc(C2=C(c3cn(CCCSC(=N)N)c4ccccc34)C(=O)NC2=O)c2ccccc21\",\n",
    "           \"O=[N+]([O-])c1ccc2[nH]c(CNc3nc(N4CCOCC4)nc4c3ncn4-c3ccsc3)nc2c1\",\n",
    "           \"Cn1c(=O)cc(OCCCC(=O)Nc2cc(C(F)(F)F)ccn2)c2ccccc21\",\n",
    "           \"FC(F)(F)c1ccc2[nH]c(CNc3nc(N4CCOCC4)nc4c3ncn4-c3ccsc3)nc2c1\",\n",
    "           \"CCC1(O)C(=O)OCc2c1cc1n(c2=O)Cc2cc3c(CN(C)C)c(O)ccc3nc2-1\",\n",
    "           \"OCCCNc1cc(-c2ccnc(Nc3cccc(Cl)c3)n2)ccn1\",\n",
    "           \"N#Cc1cc(-c2ccnc(Nc3ccc(-n4cnc(-c5cccnc5)n4)cc3)n2)cc(N2CCOCC2)c1\",\n",
    "           \"CN(c1ncccc1CNc1nc(Nc2ccc3c(c2)CC(=O)N3)ncc1C(F)(F)F)S(C)(=O)=O\",\n",
    "           \"Cc1ccc(F)c(NC(=O)Nc2ccc(-c3cccc4[nH]nc(N)c34)cc2)c1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_atom_query_ensembled(smi_query,smis_list,smiles,X_atoms, X_bonds, X_edges,NUM):\n",
    "    \n",
    "    #Smiles are the already tensorised smiles of the training which are neighbors of the query smile\n",
    "    from math import log,exp\n",
    "\n",
    "    m2=Chem.MolFromSmiles(smi_query[0])\n",
    "    n2=m2.GetNumAtoms()\n",
    "    atom_2,bond_2,edge_2=tensorise_smiles(smi_query[0:1], max_degree=5, max_atoms = 60)\n",
    "    \n",
    "    all_imps2=[]\n",
    "    all_imps1=[]\n",
    "    kk=1\n",
    "    \n",
    "    for mod in range(50):\n",
    "        print('Find counts for Model:%s'%mod)\n",
    "        siamese_net.compile(optimizer= adam,loss= custom_loss(sigma))\n",
    "        #sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        K.set_session(sess)\n",
    "        siamese_net.load_weights(f'../../deepSIBA/learning/trained_models/a375/alldata/models/siam_no_augment_{mod}.h5')\n",
    "        outputTensor = siamese_net.output\n",
    "        inputTensor = siamese_net.input\n",
    "        grad = K.gradients(outputTensor, inputTensor)\n",
    "        grad = [grad[0],grad[1],grad[3],grad[4]]\n",
    "\n",
    "        for q in range(len(smis_list)):\n",
    "            print('Start calculating important atoms for similar %s out of %s'%(q+1,len(smis_list)))\n",
    "            m1=Chem.MolFromSmiles(smis_list[q])\n",
    "            n1=m1.GetNumAtoms()\n",
    "            counter=smiles.index(smis_list[q])\n",
    "\n",
    "\n",
    "            atom_1=X_atoms[counter:counter+1]\n",
    "            bond_1=X_bonds[counter:counter+1]\n",
    "            edge_1=X_edges[counter:counter+1]\n",
    "        \n",
    "            eval_grad = sess.run(grad,\n",
    "                                 {'atom_inputs_1:0':atom_1,'bond_inputs_1:0':bond_1,'edge_inputs_1:0':edge_1,'atom_inputs_2:0':atom_2,\n",
    "                                  'bond_inputs_2:0':bond_2,'edge_inputs_2:0':edge_2})    \n",
    "            \n",
    "            DaY=(eval_grad[2][0]*atom_2[0]).sum(axis=1)\n",
    "            atoms_grad2=np.copy(DaY)\n",
    "            import operator\n",
    "            cc={}\n",
    "            for x in range(n2):\n",
    "                c=atoms_grad2[x]\n",
    "                cc.update({x:c})\n",
    "        \n",
    "            sorted_at2=sorted(cc.items(), key=operator.itemgetter(1))\n",
    "            if (np.where(DaY>0)[0].shape[0]>=(len(sorted_at2)-round(len(sorted_at2)-NUM*n2))):\n",
    "                sorted_at2=sorted_at2[round(len(sorted_at2)-NUM*n2):len(sorted_at2)]\n",
    "            else:\n",
    "                beg=np.where(DaY>0)[0].shape[0]\n",
    "                sorted_at2=sorted_at2[beg:len(sorted_at2)]\n",
    "\n",
    "            atom_ind2=[]\n",
    "            for x in sorted_at2:\n",
    "                atom_ind2.append(x[0])\n",
    "\n",
    "            #Find intersect of important atoms    \n",
    "            if kk==1:\n",
    "                all_imps2=atom_ind2.copy()\n",
    "            else:\n",
    "                all_imps2=all_imps2+atom_ind2 \n",
    "            kk+=1\n",
    " \n",
    "        print('Ended counts for model:%s'%mod)\n",
    "        \n",
    "    \n",
    "    print('Ended ensembled important atoms calculation')\n",
    "    counts=[]\n",
    "    for x in range(n2):\n",
    "        counts.append(all_imps2.count(x))\n",
    "    counts=np.array(counts)\n",
    "        \n",
    "        \n",
    "        \n",
    "    colors_at2={}\n",
    "    colors_at2,atom_ind2=atoms_colors(m2,counts,colors_at2,n2)\n",
    "    \n",
    "    output_dict={\"counts\":counts,\"atoms\":atom_ind2,\"colors\":colors_at2}\n",
    "    print('END')\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Smiles are the already tensorised smiles of the training which are neighbors of the query smile\n",
    "NUM=0.3 # percentage of top importants\n",
    "out=imp_atom_query_ensembled(smi_query,smis_list,smiles,X_atoms, X_bonds, X_edges,NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"400px\" version=\"1.1\" width=\"800px\" xml:space=\"preserve\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:rdkit=\"http://www.rdkit.org/xml\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<rect height=\"400\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"800\" x=\"0\" y=\"0\"> </rect>\n",
       "<ellipse cx=\"93.2999\" cy=\"117.326\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FFFD00;fill-rule:evenodd;stroke:#FFFD00;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"159.544\" cy=\"112.359\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FFB600;fill-rule:evenodd;stroke:#FFB600;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"196.967\" cy=\"167.244\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FF9800;fill-rule:evenodd;stroke:#FF9800;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"263.211\" cy=\"162.277\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FFB700;fill-rule:evenodd;stroke:#FFB700;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"395.698\" cy=\"152.343\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FF7500;fill-rule:evenodd;stroke:#FF7500;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"309.237\" cy=\"331.9\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FF9A00;fill-rule:evenodd;stroke:#FF9A00;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"412.905\" cy=\"381.818\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FF0000;fill-rule:evenodd;stroke:#FF0000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"565.609\" cy=\"197.294\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FF5A00;fill-rule:evenodd;stroke:#FF5A00;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"669.277\" cy=\"247.213\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FFCD00;fill-rule:evenodd;stroke:#FFCD00;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"698.097\" cy=\"187.36\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FF8200;fill-rule:evenodd;stroke:#FF8200;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"594.43\" cy=\"137.442\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FFB900;fill-rule:evenodd;stroke:#FFB900;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"540.612\" cy=\"18.1818\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FFD700;fill-rule:evenodd;stroke:#FFD700;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<ellipse cx=\"617.556\" cy=\"55.2326\" rx=\"17.7146\" ry=\"17.7146\" style=\"fill:#FFD800;fill-rule:evenodd;stroke:#FFD800;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 93.2999,117.326 159.544,112.359\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 159.544,112.359 196.967,167.244\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 196.967,167.244 263.211,162.277\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 263.211,162.277 300.634,217.162\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 300.634,217.162 366.878,212.195\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 366.878,212.195 395.698,152.343\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 383.172,208.981 403.346,167.085\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;stroke-dasharray:6,6\"/>\n",
       "<path d=\"M 366.878,212.195 404.302,267.081\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 383.469,212.943 409.665,251.363\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;stroke-dasharray:6,6\"/>\n",
       "<path d=\"M 395.698,152.343 461.942,147.376\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 406.628,164.847 452.999,161.37\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;stroke-dasharray:6,6\"/>\n",
       "<path d=\"M 461.942,147.376 499.366,202.261\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 456.579,163.093 482.775,201.513\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;stroke-dasharray:6,6\"/>\n",
       "<path d=\"M 461.942,147.376 474.547,121.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 474.547,121.2 487.151,95.0237\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 499.366,202.261 470.545,262.114\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 483.072,205.475 462.898,247.372\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;stroke-dasharray:6,6\"/>\n",
       "<path d=\"M 499.366,202.261 565.609,197.294\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 470.545,262.114 486.7,285.806\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 486.7,285.806 502.855,309.499\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 470.545,262.114 404.302,267.081\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 459.615,249.61 413.245,253.087\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;stroke-dasharray:6,6\"/>\n",
       "<path d=\"M 404.302,267.081 375.481,326.933\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 374.984,320.308 345.365,322.529\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 345.365,322.529 315.745,324.75\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 375.978,333.557 346.358,335.778\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 346.358,335.778 316.739,337.999\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 375.481,326.933 391.636,350.626\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 391.636,350.626 407.791,374.318\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 565.609,197.294 603.033,252.18\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 565.609,197.294 594.43,137.442\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 603.033,252.18 669.277,247.213\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 669.277,247.213 706.7,302.098\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 669.277,247.213 698.097,187.36\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 661.629,232.471 681.804,190.574\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 698.097,187.36 660.674,132.475\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 660.674,132.475 594.43,137.442\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 594.43,137.442 557.006,82.5567\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 557.006,82.5567 540.612,18.1818\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 557.006,82.5567 617.556,55.2326\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 557.006,82.5567 527.387,84.7776\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 527.387,84.7776 497.767,86.9985\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<text style=\"font-size:15px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"494.463\" y=\"324.499\"><tspan>OH</tspan></text>\n",
       "<text style=\"font-size:15px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"302.233\" y=\"339.4\"><tspan>O</tspan></text>\n",
       "<text style=\"font-size:15px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"399.399\" y=\"389.318\"><tspan>OH</tspan></text>\n",
       "<text style=\"font-size:15px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"483.758\" y=\"95.0237\"><tspan>O</tspan></text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cairosvg import svg2png\n",
    "m1=Chem.MolFromSmiles(smi_query[0])\n",
    "rdDepictor.Compute2DCoords(m1)\n",
    "drawer = rdMolDraw2D.MolDraw2DSVG(800,400)\n",
    "drawer.DrawMolecule(m1,highlightAtoms=list(map(int,out[\"atoms\"])),highlightAtomColors=out[\"colors\"],highlightBonds=[])\n",
    "drawer.FinishDrawing()\n",
    "svg = drawer.GetDrawingText().replace('svg:','')\n",
    "SVG(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_im='../results/res_imp.png'\n",
    "svg2png(bytestring=svg,write_to=out_im)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HtZmJPQC2hFY",
    "1fgBVjEe2hG4",
    "onYmvRio2hHG",
    "Vj8ZLfGt2hHJ",
    "DZ5eGXTz2hHN",
    "-gbjTY4z2hHT",
    "gO51qw7Y2hHY",
    "MfDAVfxJ2hHr",
    "fHVM2cHl2hLi",
    "QjJ1Fwdy2hLo",
    "R1D8q6q42hLt",
    "LVMgF7xd2hMM",
    "KXOmZ8Yf2hMU",
    "VJvg0oQG2hMu",
    "kaqa31TA2hOH",
    "OhErO_W52hON"
   ],
   "name": "SensitivityDerivatives.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
