{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following GPU devices are available: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)\n",
    "\n",
    "# Check available GPU devices.\n",
    "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : if you encounter an error running any of the examples below consider restarting the kernel and running this cell first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"max_atoms\" : int(60), \"num_atom_features\" : int(62), \"max_degree\" : int(5), \"num_bond_features\" : int(6),\n",
    "    \"graph_conv_width\" : [128,128,128], \"conv1d_filters\" : int(128), \"conv1d_size\" : int(29), \"dropout_encoder\" : 0.25,\n",
    "    \"conv1d_filters_dist\" : [128], \"conv1d_size_dist\" : [32], \"dropout_dist\" : 0.25, \"pool_size\" : int(4),\n",
    "    \"dense_size\" : [256,128,128], \"l2reg\" : 0.01, \"dist_thresh\" : 0.2, \"lr\" : 0.001 ,\"ConGauss\":True\n",
    "}#pool_size,dense_size aren't used in the model,but they can be used if the comments in dot_siamese_model.py are removed\n",
    "\n",
    "train_params = {\n",
    "    \"cell_line\" : \"a375\", \"split\" : \"5_fold_cv_split\", \"number_folds\" : [0],\n",
    "    \"output_dir\" : \"/home/biolab/Documents/Go distances/deepSIBA/results/test1\",\n",
    "    \"batch_size\" : int(128), \"epochs\" : int(20), \n",
    "    \"N_ensemble\" : int(10), \"nmodel_start\" : int(0), \"prec_threshold\" : 0.2,\n",
    "    \"test_value_norm\" : False,\n",
    "    \"predict_batch_size\":int(2048)\n",
    "}\n",
    "\n",
    "\n",
    "#encoder_params = {\n",
    "#        \"num_layers\" : 3,\n",
    "#        \"max_atoms\" : 60,\n",
    "#        \"num_atom_features\" : 62,\n",
    "#        \"num_atom_features_original\" : 62,\n",
    "#        \"num_bond_features\" : 6,\n",
    "#        \"max_degree\" : 5,\n",
    "#        \"conv_width\" : [128,128,128],\n",
    "#        \"fp_length\" : [96,96,96],\n",
    "#        \"activ_enc\" : \"selu\",\n",
    "#        \"activ_dec\" : \"selu\",\n",
    "#        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "#        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "#        \"losses_conv\" : {\n",
    "#                    \"neighbor_output\": \"mean_squared_error\",\n",
    "#                    \"self_output\": \"mean_squared_error\",\n",
    "#                    },\n",
    "#        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "#        \"metrics\" : \"mse\",\n",
    "#        \"loss_fp\" : \"mean_squared_error\",\n",
    "#        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "#        'callbacks' : [EarlyStopping(monitor='loss',patience=8, min_delta=0), ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)],\n",
    "#        'adam_decay': 0.0005329142291371636,\n",
    "#        'beta': 5,\n",
    "#        'p': 0.004465204118126482\n",
    "#        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0425 17:38:09.218182 140420176209728 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0425 17:38:09.223801 140420176209728 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0425 17:38:09.224492 140420176209728 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0425 17:38:09.346690 140420176209728 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0425 17:38:09.665339 140420176209728 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0425 17:38:09.729563 140420176209728 deprecation.py:506] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0425 17:38:10.569230 140420176209728 deprecation_wrapper.py:119] From /home/biolab/miniconda3/envs/tf1/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0425 17:38:10.574273 140420176209728 deprecation.py:323] From /home/biolab/Documents/Go distances/deepSIBA/learning/utility/gaussian.py:39: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0425 17:38:10.595559 140420176209728 deprecation.py:323] From /home/biolab/Documents/Go distances/deepSIBA/learning/utility/evaluator.py:53: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs_1 (InputLayer)      (None, 60, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_1 (InputLayer)      (None, 60, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_1 (InputLayer)      (None, 60, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_2 (InputLayer)      (None, 60, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_2 (InputLayer)      (None, 60, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_2 (InputLayer)      (None, 60, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 32, 128)      694144      atom_inputs_1[0][0]              \n",
      "                                                                 bond_inputs_1[0][0]              \n",
      "                                                                 edge_inputs_1[0][0]              \n",
      "                                                                 atom_inputs_2[0][0]              \n",
      "                                                                 bond_inputs_2[0][0]              \n",
      "                                                                 edge_inputs_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32, 32)       0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 128)       131072      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1, 128)       512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1, 128)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 128)       0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "main_output (ConGaussianLayer)  [(None, 1), (None, 1 258         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 825,986\n",
      "Trainable params: 824,706\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from dot_siamese_model import siamese_model,enc_graph\n",
    "siamese_net=siamese_model(model_params)\n",
    "print(siamese_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dot_siamese_train import siba_trainer\n",
    "example_1 = siba_trainer(train_params, model_params, encoder_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
