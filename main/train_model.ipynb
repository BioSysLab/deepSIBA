{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egYX2aATTDiK"
   },
   "source": [
    "# Load libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubBgA0SXLYnl"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from comet_ml import Experiment\n",
    "import numpy as np\n",
    "from numpy import inf, ndarray\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import keras\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import re\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model, Model\n",
    "from tempfile import TemporaryFile\n",
    "from keras import layers\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors\n",
    "from keras.callbacks import History, ReduceLROnPlateau\n",
    "from keras.layers import Input, BatchNormalization, Activation\n",
    "from keras.layers import CuDNNLSTM, Dense, Bidirectional, Dropout, Layer\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.regularizers import l2\n",
    "from functools import partial\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from copy import deepcopy\n",
    "from NGF.utils import filter_func_args, mol_shapes_to_dims\n",
    "import NGF.utils\n",
    "import NGF_layers.features\n",
    "import NGF_layers.graph_layers\n",
    "from NGF_layers.features import one_of_k_encoding, one_of_k_encoding_unk, atom_features, bond_features, num_atom_features, num_bond_features\n",
    "from NGF_layers.features import padaxis, tensorise_smiles, concat_mol_tensors\n",
    "from NGF_layers.graph_layers import temporal_padding, neighbour_lookup, NeuralGraphHidden, NeuralGraphOutput\n",
    "from math import ceil\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from utility.gaussian import GaussianLayer\n",
    "from utility.gaussian import custom_loss\n",
    "from utility.evaluator import r_square, get_cindex, pearson_r, mse_sliced, model_evaluate\n",
    "from utility.Generator import train_generator\n",
    "from model import enc_mols, net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRWlUdzxUJ3e"
   },
   "source": [
    "# Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckmCcQT3UMNz"
   },
   "outputs": [],
   "source": [
    "#Load unique smiles and tensorize them\n",
    "smiles = pd.read_csv('data/a375q1/80dr_cold3/alla375q1smiles.csv',index_col=0)\n",
    "\n",
    "X_atoms, X_bonds, X_edges = tensorise_smiles(smiles.x, max_degree=5, max_atoms = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwZGzl08UM33"
   },
   "outputs": [],
   "source": [
    "smiles=list(smiles['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RvZDS2MDT10K"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVArTy7aT3DZ"
   },
   "outputs": [],
   "source": [
    "p = {'lr': 0.0001,\n",
    "     'nfilters': int(32),\n",
    "     'size': int(8),\n",
    "     'conv_width' : 128,\n",
    "     'fp_length' : 256,\n",
    "     'size_drug_1' : 8,\n",
    "     'size_drug_2' : 4,\n",
    "     'size_protein_1' : 8,\n",
    "     'size_protein_2' : 16,\n",
    "     'size_protein_3' : 3,\n",
    "     'batch_size': int(128),\n",
    "     'dense_size': int(256),\n",
    "     'dense_size_2': 512,\n",
    "     'dropout': 0.25,\n",
    "     'l2reg': 0.01}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YcQJfqsgUbLv"
   },
   "source": [
    "# Load Cold validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2aaBIDDT4NZ"
   },
   "outputs": [],
   "source": [
    "num_molecules = len(df)\n",
    "max_atoms = 60\n",
    "max_degree = 5\n",
    "num_atom_features = 62\n",
    "num_bond_features = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JXhbFznUfce"
   },
   "outputs": [],
   "source": [
    "df_cold = pd.read_csv('data/pc3q1/80dr_cold/cold_val_21_10.csv',index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLpl-JH_U0SL"
   },
   "outputs": [],
   "source": [
    "smiles_cold = df_cold['rdkit.x']\n",
    "smiles_cold2 = df_cold['rdkit.y']\n",
    "X_atoms_cold_1, X_bonds_cold_1, X_edges_cold_1 = tensorise_smiles(smiles_cold, max_degree=5, max_atoms = 60)\n",
    "X_atoms_cold_2, X_bonds_cold_2, X_edges_cold_2 = tensorise_smiles(smiles_cold2, max_degree=5, max_atoms = 60)\n",
    "Y_cold = df_cold.value\n",
    "Y_cold = Y_cold/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38w8Y_DzU1XW"
   },
   "source": [
    "# Fit ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9NOXgvhU3tH"
   },
   "outputs": [],
   "source": [
    "cold_preds_mus=[]\n",
    "cold_preds_sigmas=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUd8VKWjU51T"
   },
   "outputs": [],
   "source": [
    "for n in range(50):\n",
    "    # Initialize encoder\n",
    "    encoder_mols = enc_mols(p, 0.001, 128, 256)\n",
    "    \n",
    "    #Use net defined in model.py\n",
    "    siamese_net=net(max_atoms, num_atom_features,max_degree, num_bond_features,encoder_mols)\n",
    "    adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "    siamese_net.compile(optimizer= adam,loss= custom_loss(sigma),metrics=['mse', get_cindex, r_square, pearson_r, mse_sliced])\n",
    "    \n",
    "    #Load Weights\n",
    "    #siamese_net.load_weights('models/Nick_ensembles_no_augm/models/siam_ens_10.h5')\n",
    "    \n",
    "    # Augment dataset\n",
    "    #df_new = augment(df_rest,df,1)\n",
    "    \n",
    "    # Train with fitgen\n",
    "    rlr = ReduceLROnPlateau(monitor='loss', factor=0.5,patience=2, min_lr=0.00001, verbose=1, min_delta=1e-5)\n",
    "    term=keras.callbacks.TerminateOnNaN()\n",
    "    bs=128\n",
    "    NUM_EPOCHS = 10\n",
    "    #df_new = df_new.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    #Set total number of training samples and tests samples\n",
    "    NUM_TRAIN = len(df)\n",
    "    trainGen=train_generator(bs,df,smiles,X_atoms, X_bonds, X_edges)\n",
    "    siamese_net.fit_generator(trainGen,\n",
    "                        steps_per_epoch= ceil(NUM_TRAIN/bs),\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        verbose = 1,\n",
    "                        validation_data = ([X_atoms_cold_1,X_bonds_cold_1,X_edges_cold_1,X_atoms_cold_2, X_bonds_cold_2, X_edges_cold_2],Y_cold),\n",
    "                        shuffle = True,\n",
    "                        callbacks= [term, rlr])\n",
    "    \n",
    "    # Save model\n",
    "    siamese_net.save_weights('models/Nick_ensembles_no_augm_pc3_pretrained_in_mcf7/models/siam_no_augment_%s.h5'%n)\n",
    "    # Decouple model at the gaussian\n",
    "    Gauss = keras.Model(siamese_net.inputs, siamese_net.get_layer('main_output').output)\n",
    "    # evaluate and save evals\n",
    "    y_pred = siamese_net.predict([X_atoms_cold_1,X_bonds_cold_1,X_edges_cold_1,X_atoms_cold_2, X_bonds_cold_2, X_edges_cold_2],batch_size=2048)\n",
    "    get = model_evaluate(y_pred,Y_cold)\n",
    "    get.to_csv('models/Nick_ensembles_no_augm_pc3_pretrained_in_mcf7/performance/Model_No_%s.csv'%n)\n",
    "    # Predict on cold\n",
    "    cold_pred = Gauss.predict([X_atoms_cold_1,X_bonds_cold_1,X_edges_cold_1,X_atoms_cold_2, X_bonds_cold_2, X_edges_cold_2],batch_size=2048)\n",
    "    # Append mus and sigmas and save at the same time\n",
    "    cold_preds_mus.append(cold_pred[0])\n",
    "    np.save('models/Nick_ensembles_no_augm_pc3_pretrained_in_mcf7/cold/mu/cold_mu_No_%s.npy'%n, cold_pred[0])\n",
    "    cold_preds_sigmas.append(cold_pred[1])\n",
    "    np.save('models/Nick_ensembles_no_augm_pc3_pretrained_in_mcf7/cold/sigma/cold_sigma_No_%s.npy'%n, cold_pred[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
